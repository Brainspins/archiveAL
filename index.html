<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Active Listening Archive</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <div id="top-bar">
    <button id="mode-switcher">Glitch Mode</button>
  </div>

  <div id="instruction" style="display:none;">
    <p>Turn on the sound and move your cursor across the grid. Get the sound and compare it with the text.</p>
    <p>Errors of transcription are not mistakes here. They are exits, lines of flight, small escapes from control.</p>
    <p>The makers are open-source systems: pretrained AI Stable Diffusion 1.5 model for images, Whisper for transcription, ControlNet for conditioning, and a UTF-8 decoder for text.</p>
    <p>The archive preserves outputs - transcripts, ads, and audio - as records of how machines mishear and misinterpret us and our environment.</p>
  </div>

  <div id="gallery"></div>
  <div id="glitch-grid" style="display:none;"></div>

  <script src="script.js"></script>
</body>
</html>

